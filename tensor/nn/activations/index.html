<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-tensor docs-doc-id-nn/activations">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Activations | NumPower</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://numpower.org/tensor/nn/activations"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-tensor-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-tensor-current"><meta data-rh="true" property="og:title" content="Activations | NumPower"><meta data-rh="true" name="description" content="Activation functions are mathematical functions used in neural networks to introduce non-linearity into the model."><meta data-rh="true" property="og:description" content="Activation functions are mathematical functions used in neural networks to introduce non-linearity into the model."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://numpower.org/tensor/nn/activations"><link data-rh="true" rel="alternate" href="https://numpower.org/tensor/nn/activations" hreflang="en"><link data-rh="true" rel="alternate" href="https://numpower.org/tensor/nn/activations" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.cc1eeb4a.css">
<link rel="preload" href="/assets/js/runtime~main.c6add0a5.js" as="script">
<link rel="preload" href="/assets/js/main.765e0f4e.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/numpower.png" alt="" class="themedImage_ToTc themedImage--light_HNdA" height="32" width="32"><img src="/img/numpower_white.png" alt="" class="themedImage_ToTc themedImage--dark_i4oU" height="32" width="32"></div><b class="navbar__title text--truncate">NumPower</b></a><a class="navbar__item navbar__link" href="/install/install">Getting Started</a><a class="navbar__item navbar__link" href="/docs/intro">Documentation</a><a class="navbar__item navbar__link" href="/api/intro">API</a><a class="navbar__item navbar__link" href="/tensor/category/numpower-autograd">Autograd</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/NumPower/numpower" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input type="search" id="search_input_react" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/tensor/category/numpower-autograd">NumPower Autograd</a><button aria-label="Toggle the collapsible sidebar category &#x27;NumPower Autograd&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/tensor/category/api">API</a><button aria-label="Toggle the collapsible sidebar category &#x27;API&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/tensor/category/neural-network-module">Neural Network Module</a><button aria-label="Toggle the collapsible sidebar category &#x27;Neural Network Module&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/tensor/nn/losses">Losses</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/tensor/nn/activations">Activations</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/tensor/category/low-level-classes-and-operations">Low-level Classes and Operations</a><button aria-label="Toggle the collapsible sidebar category &#x27;Low-level Classes and Operations&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/tensor/category/neural-network-module"><span itemprop="name">Neural Network Module</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Activations</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Activations</h1><p>Activation functions are mathematical functions used in neural networks to introduce non-linearity into the model.
This non-linearity enables the network to learn complex patterns and relationships in the data. Activation
functions are applied to the output of each neuron, determining whether that neuron should be activated or not.</p><p>Activation functions can be found through static calls in the class <code>NumPower\NeuralNetwork\Activations;</code>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="non-linear-activations">Non-Linear Activations<a href="#non-linear-activations" class="hash-link" aria-label="Direct link to Non-Linear Activations" title="Direct link to Non-Linear Activations">​</a></h2><hr><h3 class="anchor anchorWithStickyNavbar_LWe7" id="tanh">tanh<a href="#tanh" class="hash-link" aria-label="Direct link to tanh" title="Direct link to tanh">​</a></h3><div class="language-php codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-php codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">public</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">static</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">function</span><span class="token plain"> </span><span class="token function-definition function" style="color:rgb(80, 250, 123)">tanh</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">array</span><span class="token operator">|</span><span class="token class-name class-name-fully-qualified punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token class-name class-name-fully-qualified">NDArray</span><span class="token operator">|</span><span class="token class-name">Tensor</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$x</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">string</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$name</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string single-quoted-string" style="color:rgb(255, 121, 198)">&#x27;out_tanh&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token class-name return-type">Tensor</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This function computes the hyperbolic tangent (tanh) activation function on the provided input.
Tanh transforms each element of the input tensor using the hyperbolic tangent function, which maps
values to the range (-1, 1). It is useful for normalizing inputs in neural networks and other computational models,
providing a smooth transition between negative and positive values.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="softplus">softplus<a href="#softplus" class="hash-link" aria-label="Direct link to softplus" title="Direct link to softplus">​</a></h3><div class="language-php codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-php codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">public</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">static</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">function</span><span class="token plain"> </span><span class="token function-definition function" style="color:rgb(80, 250, 123)">softplus</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">array</span><span class="token operator">|</span><span class="token class-name class-name-fully-qualified punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token class-name class-name-fully-qualified">NDArray</span><span class="token operator">|</span><span class="token class-name">Tensor</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$x</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">string</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$name</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string single-quoted-string" style="color:rgb(255, 121, 198)">&#x27;out_softplus&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token class-name return-type">Tensor</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This function computes the Softplus activation function on the provided input. Softplus transforms each element of
the input tensor using the natural logarithm of the sum of the exponential of the element and one. This operation
smooths out the output, ensuring it is always positive.</p><p>The resulting tensor, with the same shape as the input, represents the output of the softplus operation.
The optional parameter $name specifies the name of the output tensor and defaults to &#x27;out_softplus&#x27;.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="softmax">softmax<a href="#softmax" class="hash-link" aria-label="Direct link to softmax" title="Direct link to softmax">​</a></h3><div class="language-php codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-php codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">public</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">static</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">function</span><span class="token plain"> </span><span class="token function-definition function" style="color:rgb(80, 250, 123)">softmax</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">array</span><span class="token operator">|</span><span class="token class-name class-name-fully-qualified punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token class-name class-name-fully-qualified">NDArray</span><span class="token operator">|</span><span class="token class-name">Tensor</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$x</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">string</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$name</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string single-quoted-string" style="color:rgb(255, 121, 198)">&#x27;out_softmax&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token class-name return-type">Tensor</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This function computes the softmax activation function on the provided input. Softmax transforms each element of
the input tensor into a probability distribution by exponentiating each element and then normalizing the
tensor so that the sum of all elements equals one. This makes softmax suitable for multi-class classification tasks,
where it outputs probabilities for each class.</p><p>The resulting tensor, with the same shape as the input, represents the output of the softmax operation.
The optional parameter $name specifies the name of the output tensor and defaults to &#x27;out_softmax&#x27;.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="softsign">softsign<a href="#softsign" class="hash-link" aria-label="Direct link to softsign" title="Direct link to softsign">​</a></h3><div class="language-php codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-php codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">public</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">static</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">function</span><span class="token plain"> </span><span class="token function-definition function" style="color:rgb(80, 250, 123)">softsign</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">array</span><span class="token operator">|</span><span class="token class-name class-name-fully-qualified punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token class-name class-name-fully-qualified">NDArray</span><span class="token operator">|</span><span class="token class-name">Tensor</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$x</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">string</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$name</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string single-quoted-string" style="color:rgb(255, 121, 198)">&#x27;out_softsign&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token class-name return-type">Tensor</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This function computes the Softsign activation function on the provided input.
The softsign function transforms each element of the input tensor by dividing it by the absolute value of
itself plus one. This transformation maps the input values to the range (-1, 1), preserving zero.</p><p>The resulting tensor, with the same shape as the input, represents the output of the softsign operation.
The optional parameter $name specifies the name of the output tensor and defaults to &#x27;out_sigmoid&#x27;.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="relu">ReLU<a href="#relu" class="hash-link" aria-label="Direct link to ReLU" title="Direct link to ReLU">​</a></h3><div class="language-php codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-php codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">public</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">static</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">function</span><span class="token plain"> </span><span class="token function-definition function" style="color:rgb(80, 250, 123)">ReLU</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">array</span><span class="token operator">|</span><span class="token class-name class-name-fully-qualified punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token class-name class-name-fully-qualified">NDArray</span><span class="token operator">|</span><span class="token class-name">Tensor</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$inputs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">string</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$name</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string single-quoted-string" style="color:rgb(255, 121, 198)">&#x27;out_relu&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token class-name return-type">Tensor</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This function implements the Rectified Linear Unit (ReLU) activation function for a given tensor of inputs.
ReLU activation sets all negative values in the tensor to zero, leaving positive values unchanged.
The function returns a tensor with the same shape as the input tensor, representing the output of the ReLU
operation. The optional parameter $name specifies the name of the output tensor and defaults to &#x27;out_relu&#x27;.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="celu">CELU<a href="#celu" class="hash-link" aria-label="Direct link to CELU" title="Direct link to CELU">​</a></h3><div class="language-php codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-php codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">public</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">static</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">function</span><span class="token plain"> </span><span class="token function-definition function" style="color:rgb(80, 250, 123)">CELU</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">array</span><span class="token operator">|</span><span class="token class-name class-name-fully-qualified punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token class-name class-name-fully-qualified">NDArray</span><span class="token operator">|</span><span class="token class-name">Tensor</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$x</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                            </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$alpha</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">1.0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                            </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">string</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$name</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string single-quoted-string" style="color:rgb(255, 121, 198)">&#x27;out_celu&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token class-name return-type">Tensor</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This function computes the Continuous Exponential Linear Unit (CELU) activation function on the provided input.
CELU applies a non-linear transformation that smooths negative values of the input tensor based on
the parameter $alpha, while leaving positive values unchanged.</p><p>The resulting tensor, with the same shape as the input, represents the output of the CELU operation.
The optional parameter $name specifies the name of the output tensor and defaults to &#x27;out_celu&#x27;.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="silu">SiLU<a href="#silu" class="hash-link" aria-label="Direct link to SiLU" title="Direct link to SiLU">​</a></h3><div class="language-php codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-php codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">public</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">static</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">function</span><span class="token plain"> </span><span class="token function-definition function" style="color:rgb(80, 250, 123)">SiLU</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">array</span><span class="token operator">|</span><span class="token class-name class-name-fully-qualified punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token class-name class-name-fully-qualified">NDArray</span><span class="token operator">|</span><span class="token class-name">Tensor</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$x</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                            </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$beta</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">1.0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                            </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">string</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$name</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string single-quoted-string" style="color:rgb(255, 121, 198)">&#x27;out_silu&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token class-name return-type">Tensor</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This function computes the Sigmoid-weighted Linear Unit (SiLU), also known as the Swish activation function,
on the provided input. SiLU applies a non-linear transformation that smooths negative values of the input tensor
based on the parameter $beta, using a sigmoid function, while preserving positive values unchanged.</p><p>The resulting tensor, with the same shape as the input, represents the output of the SiLU operation.
The optional parameter $name specifies the name of the output tensor and defaults to &#x27;out_silu&#x27;.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="selu">SELU<a href="#selu" class="hash-link" aria-label="Direct link to SELU" title="Direct link to SELU">​</a></h3><div class="language-php codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-php codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">public</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">static</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">function</span><span class="token plain"> </span><span class="token function-definition function" style="color:rgb(80, 250, 123)">SELU</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">array</span><span class="token operator">|</span><span class="token class-name class-name-fully-qualified punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token class-name class-name-fully-qualified">NDArray</span><span class="token operator">|</span><span class="token class-name">Tensor</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$inputs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                            </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$alpha</span><span class="token operator">=</span><span class="token number">1.67326</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                            </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$scale</span><span class="token operator">=</span><span class="token number">1.0507</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                            </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">string</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$name</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string single-quoted-string" style="color:rgb(255, 121, 198)">&#x27;out_selu&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token class-name return-type">Tensor</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This function applies the Scaled Exponential Linear Unit (SELU) activation function to a tensor of inputs.
SELU applies a scaled version of the Exponential Linear Unit (ELU), transforming each element of the
input tensor based on the parameters $alpha and $scale. The function returns a tensor with the same shape
as the input tensor, representing the output of the SELU operation. The optional parameter $name specifies
the name of the output tensor and defaults to &#x27;out_selu&#x27;.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="exponential">exponential<a href="#exponential" class="hash-link" aria-label="Direct link to exponential" title="Direct link to exponential">​</a></h3><div class="language-php codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-php codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">public</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">static</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">function</span><span class="token plain"> </span><span class="token function-definition function" style="color:rgb(80, 250, 123)">exponential</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">array</span><span class="token operator">|</span><span class="token class-name class-name-fully-qualified punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token class-name class-name-fully-qualified">NDArray</span><span class="token operator">|</span><span class="token class-name">Tensor</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$x</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">string</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$name</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string single-quoted-string" style="color:rgb(255, 121, 198)">&#x27;out_exponential&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token class-name return-type">Tensor</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This function computes the exponential function on the provided input. The exponential function raises the mathematical constant
𝑒 (approximately 2.718) to the power of each element in the input tensor. This operation is commonly used in various mathematical and statistical computations.</p><p>The resulting tensor, with the same shape as the input, represents the output of the exponential operation.
The optional parameter $name specifies the name of the output tensor and defaults to &#x27;out_exponential&#x27;.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="mish">mish<a href="#mish" class="hash-link" aria-label="Direct link to mish" title="Direct link to mish">​</a></h3><div class="language-php codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-php codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">public</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">static</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">function</span><span class="token plain"> </span><span class="token function-definition function" style="color:rgb(80, 250, 123)">mish</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">array</span><span class="token operator">|</span><span class="token class-name class-name-fully-qualified punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token class-name class-name-fully-qualified">NDArray</span><span class="token operator">|</span><span class="token class-name">Tensor</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$x</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">string</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$name</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string single-quoted-string" style="color:rgb(255, 121, 198)">&#x27;out_mish&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token class-name return-type">Tensor</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This function computes the Mish activation function on the provided input. Mish is a relatively newer activation
function that smooths and enhances the training of neural networks by introducing a non-linearity
that is differentiable and has favorable properties during gradient descent.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sigmoid">sigmoid<a href="#sigmoid" class="hash-link" aria-label="Direct link to sigmoid" title="Direct link to sigmoid">​</a></h3><div class="language-php codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-php codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">public</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">static</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">function</span><span class="token plain"> </span><span class="token function-definition function" style="color:rgb(80, 250, 123)">sigmoid</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">array</span><span class="token operator">|</span><span class="token class-name class-name-fully-qualified punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token class-name class-name-fully-qualified">NDArray</span><span class="token operator">|</span><span class="token class-name">Tensor</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$x</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">string</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$name</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string single-quoted-string" style="color:rgb(255, 121, 198)">&#x27;out_sigmoid&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token class-name return-type">Tensor</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This function computes the sigmoid activation function on the provided input.
The sigmoid function transforms each element of the input tensor to a value between 0 and 1,
representing the probability-like output of a binary classification decision.</p><p>The resulting tensor, with the same shape as the input, represents the output of the sigmoid operation.
The optional parameter $name specifies the name of the output tensor and defaults to &#x27;out_sigmoid&#x27;.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="linear-activations">Linear Activations<a href="#linear-activations" class="hash-link" aria-label="Direct link to Linear Activations" title="Direct link to Linear Activations">​</a></h2><hr><p>A linear activation function, also known as an identity activation function, is a function where the output is
directly proportional to the input. In mathematical terms, if the input to the function is 𝑥, the output is also 𝑥.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="linear">Linear<a href="#linear" class="hash-link" aria-label="Direct link to Linear" title="Direct link to Linear">​</a></h3><div class="language-php codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-php codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">public</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">static</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">function</span><span class="token plain"> </span><span class="token function-definition function" style="color:rgb(80, 250, 123)">linear</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">float</span><span class="token operator">|</span><span class="token keyword type-declaration" style="color:rgb(189, 147, 249);font-style:italic">array</span><span class="token operator">|</span><span class="token class-name class-name-fully-qualified punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token class-name class-name-fully-qualified">NDArray</span><span class="token operator">|</span><span class="token class-name">Tensor</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$x</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token keyword type-hint" style="color:rgb(189, 147, 249);font-style:italic">string</span><span class="token plain"> </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$name</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string single-quoted-string" style="color:rgb(255, 121, 198)">&#x27;out_linear&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token class-name return-type">Tensor</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This function represents the identity or linear activation function, which simply returns the input tensor
𝑥  unchanged. It is used when no activation function is desired or required in a specific layer of a neural
network or any other computational graph.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/tensor/nn/losses"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Losses</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/tensor/category/low-level-classes-and-operations"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Low-level Classes and Operations</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#non-linear-activations" class="table-of-contents__link toc-highlight">Non-Linear Activations</a><ul><li><a href="#tanh" class="table-of-contents__link toc-highlight">tanh</a></li><li><a href="#softplus" class="table-of-contents__link toc-highlight">softplus</a></li><li><a href="#softmax" class="table-of-contents__link toc-highlight">softmax</a></li><li><a href="#softsign" class="table-of-contents__link toc-highlight">softsign</a></li><li><a href="#relu" class="table-of-contents__link toc-highlight">ReLU</a></li><li><a href="#celu" class="table-of-contents__link toc-highlight">CELU</a></li><li><a href="#silu" class="table-of-contents__link toc-highlight">SiLU</a></li><li><a href="#selu" class="table-of-contents__link toc-highlight">SELU</a></li><li><a href="#exponential" class="table-of-contents__link toc-highlight">exponential</a></li><li><a href="#mish" class="table-of-contents__link toc-highlight">mish</a></li><li><a href="#sigmoid" class="table-of-contents__link toc-highlight">sigmoid</a></li></ul></li><li><a href="#linear-activations" class="table-of-contents__link toc-highlight">Linear Activations</a><ul><li><a href="#linear" class="table-of-contents__link toc-highlight">Linear</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">© 2024 <a href="https://github.com/henrique-borba">Henrique Borba</a>. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.c6add0a5.js"></script>
<script src="/assets/js/main.765e0f4e.js"></script>
</body>
</html>