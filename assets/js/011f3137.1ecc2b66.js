"use strict";(self.webpackChunknumpower=self.webpackChunknumpower||[]).push([[1746],{36359:i=>{i.exports=JSON.parse('{"pluginId":"tensor","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"apiSidebar":[{"type":"category","label":"NumPower Autograd","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"What is Automatic Differentiation (Autograd)?","href":"/tensor/intro/autograd-intro","docId":"intro/autograd-intro"},{"type":"link","label":"Installing Autograd","href":"/tensor/intro/installing","docId":"intro/installing"},{"type":"link","label":"Basic usage","href":"/tensor/intro/basic-usage","docId":"intro/basic-usage"},{"type":"link","label":"Simple Neural Net from scratch using Autograd","href":"/tensor/intro/autograd-model","docId":"intro/autograd-model"}],"href":"/tensor/category/numpower-autograd"},{"type":"category","label":"API","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Tensor API","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"toArray","href":"/tensor/api/tensor/toArray","docId":"api/tensor/toArray"},{"type":"link","label":"detach","href":"/tensor/api/tensor/detach","docId":"api/tensor/detach"},{"type":"link","label":"getData","href":"/tensor/api/tensor/getData","docId":"api/tensor/getData"},{"type":"link","label":"isGPU","href":"/tensor/api/tensor/isGPU","docId":"api/tensor/isGPU"},{"type":"link","label":"getName","href":"/tensor/api/tensor/getName","docId":"api/tensor/getName"},{"type":"link","label":"getShape","href":"/tensor/api/tensor/getShape","docId":"api/tensor/getShape"},{"type":"link","label":"grad","href":"/tensor/api/tensor/grad","docId":"api/tensor/grad"},{"type":"link","label":"graph","href":"/tensor/api/tensor/graph","docId":"api/tensor/graph"},{"type":"link","label":"isScalar","href":"/tensor/api/tensor/isScalar","docId":"api/tensor/isScalar"},{"type":"link","label":"numElements","href":"/tensor/api/tensor/numElements","docId":"api/tensor/numElements"},{"type":"link","label":"requireGrad","href":"/tensor/api/tensor/requireGrad","docId":"api/tensor/requireGrad"},{"type":"link","label":"resetGradients","href":"/tensor/api/tensor/resetGradients","docId":"api/tensor/resetGradients"},{"type":"link","label":"getTape","href":"/tensor/api/tensor/getTape","docId":"api/tensor/getTape"},{"type":"link","label":"backward","href":"/tensor/api/tensor/backward","docId":"api/tensor/backward"}],"href":"/tensor/category/tensor-api"},{"type":"category","label":"Arithmetics","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"add","href":"/tensor/api/arithmetics/add","docId":"api/arithmetics/add"},{"type":"link","label":"divide","href":"/tensor/api/arithmetics/divide","docId":"api/arithmetics/divide"},{"type":"link","label":"mod","href":"/tensor/api/arithmetics/mod","docId":"api/arithmetics/mod"},{"type":"link","label":"multiply","href":"/tensor/api/arithmetics/multiply","docId":"api/arithmetics/multiply"},{"type":"link","label":"negative","href":"/tensor/api/arithmetics/negative","docId":"api/arithmetics/negative"},{"type":"link","label":"power","href":"/tensor/api/arithmetics/power","docId":"api/arithmetics/power"},{"type":"link","label":"subtract","href":"/tensor/api/arithmetics/subtract","docId":"api/arithmetics/subtract"},{"type":"link","label":"sum","href":"/tensor/api/arithmetics/sum","docId":"api/arithmetics/sum"},{"type":"link","label":"sum_axis","href":"/tensor/api/arithmetics/sum_axis","docId":"api/arithmetics/sum_axis"}],"href":"/tensor/category/arithmetics"},{"type":"category","label":"Exponential and Logarithms","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"exp","href":"/tensor/api/exponents/exp","docId":"api/exponents/exp"},{"type":"link","label":"exp2","href":"/tensor/api/exponents/exp2","docId":"api/exponents/exp2"},{"type":"link","label":"expm1","href":"/tensor/api/exponents/expm1","docId":"api/exponents/expm1"},{"type":"link","label":"log","href":"/tensor/api/exponents/log","docId":"api/exponents/log"},{"type":"link","label":"log10","href":"/tensor/api/exponents/log10","docId":"api/exponents/log10"},{"type":"link","label":"log1p","href":"/tensor/api/exponents/log1p","docId":"api/exponents/log1p"},{"type":"link","label":"log2","href":"/tensor/api/exponents/log2","docId":"api/exponents/log2"}],"href":"/tensor/category/exponential-and-logarithms"},{"type":"category","label":"Hyperbolic Operations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"cosh","href":"/tensor/api/hyperbolic/cosh","docId":"api/hyperbolic/cosh"},{"type":"link","label":"arccosh","href":"/tensor/api/hyperbolic/arccosh","docId":"api/hyperbolic/arccosh"},{"type":"link","label":"sinh","href":"/tensor/api/hyperbolic/sinh","docId":"api/hyperbolic/sinh"},{"type":"link","label":"arcsinh","href":"/tensor/api/hyperbolic/arcsinh","docId":"api/hyperbolic/arcsinh"},{"type":"link","label":"sinc","href":"/tensor/api/hyperbolic/sinc","docId":"api/hyperbolic/sinc"},{"type":"link","label":"arctan2","href":"/tensor/api/hyperbolic/arctan2","docId":"api/hyperbolic/arctan2"},{"type":"link","label":"arctanh","href":"/tensor/api/hyperbolic/arctanh","docId":"api/hyperbolic/arctanh"},{"type":"link","label":"tanh","href":"/tensor/api/hyperbolic/tanh","docId":"api/hyperbolic/tanh"}],"href":"/tensor/category/hyperbolic-operations"},{"type":"category","label":"Linear Algebra","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"matmul","href":"/tensor/api/linalg/matmul","docId":"api/linalg/matmul"},{"type":"link","label":"cond","href":"/tensor/api/linalg/cond","docId":"api/linalg/cond"},{"type":"link","label":"det","href":"/tensor/api/linalg/det","docId":"api/linalg/det"},{"type":"link","label":"dot","href":"/tensor/api/linalg/dot","docId":"api/linalg/dot"},{"type":"link","label":"matrix_rank","href":"/tensor/api/linalg/matrix_rank","docId":"api/linalg/matrix_rank"},{"type":"link","label":"norm","href":"/tensor/api/linalg/norm","docId":"api/linalg/norm"},{"type":"link","label":"outer","href":"/tensor/api/linalg/outer","docId":"api/linalg/outer"},{"type":"link","label":"svd","href":"/tensor/api/linalg/svd","docId":"api/linalg/svd"}],"href":"/tensor/category/linear-algebra"},{"type":"category","label":"Rounding","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"ceil","href":"/tensor/api/rounding/ceil","docId":"api/rounding/ceil"},{"type":"link","label":"clip","href":"/tensor/api/rounding/clip","docId":"api/rounding/clip"},{"type":"link","label":"floor","href":"/tensor/api/rounding/floor","docId":"api/rounding/floor"},{"type":"link","label":"trunc","href":"/tensor/api/rounding/trunc","docId":"api/rounding/trunc"}],"href":"/tensor/category/rounding"},{"type":"category","label":"Trigonometric","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"sin","href":"/tensor/api/trigonometric/sin","docId":"api/trigonometric/sin"},{"type":"link","label":"tan","href":"/tensor/api/trigonometric/tan","docId":"api/trigonometric/tan"},{"type":"link","label":"cos","href":"/tensor/api/trigonometric/cos","docId":"api/trigonometric/cos"},{"type":"link","label":"acos","href":"/tensor/api/trigonometric/acos","docId":"api/trigonometric/acos"},{"type":"link","label":"arcsin","href":"/tensor/api/trigonometric/arcsin","docId":"api/trigonometric/arcsin"},{"type":"link","label":"arctan","href":"/tensor/api/trigonometric/arctan","docId":"api/trigonometric/arctan"},{"type":"link","label":"radians","href":"/tensor/api/trigonometric/radians","docId":"api/trigonometric/radians"}],"href":"/tensor/category/trigonometric"},{"type":"category","label":"Manipulation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"reshape","href":"/tensor/api/manipulation/reshape","docId":"api/manipulation/reshape"}],"href":"/tensor/category/manipulation"}],"href":"/tensor/category/api"},{"type":"category","label":"Neural Network Module","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Losses","href":"/tensor/nn/losses","docId":"nn/losses"},{"type":"link","label":"Activations","href":"/tensor/nn/activations","docId":"nn/activations"}],"href":"/tensor/category/neural-network-module"},{"type":"category","label":"Low-level Classes and Operations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"ArithmeticOperand Class","href":"/tensor/low-level/arithmetic-operand","docId":"low-level/arithmetic-operand"}],"href":"/tensor/category/low-level-classes-and-operations"}]},"docs":{"api/arithmetics/add":{"id":"api/arithmetics/add","title":"add","description":"","sidebar":"apiSidebar"},"api/arithmetics/divide":{"id":"api/arithmetics/divide","title":"divide","description":"","sidebar":"apiSidebar"},"api/arithmetics/mod":{"id":"api/arithmetics/mod","title":"mod","description":"","sidebar":"apiSidebar"},"api/arithmetics/multiply":{"id":"api/arithmetics/multiply","title":"multiply","description":"","sidebar":"apiSidebar"},"api/arithmetics/negative":{"id":"api/arithmetics/negative","title":"negative","description":"","sidebar":"apiSidebar"},"api/arithmetics/power":{"id":"api/arithmetics/power","title":"power","description":"","sidebar":"apiSidebar"},"api/arithmetics/subtract":{"id":"api/arithmetics/subtract","title":"subtract","description":"","sidebar":"apiSidebar"},"api/arithmetics/sum":{"id":"api/arithmetics/sum","title":"sum","description":"","sidebar":"apiSidebar"},"api/arithmetics/sum_axis":{"id":"api/arithmetics/sum_axis","title":"sum_axis","description":"","sidebar":"apiSidebar"},"api/exponents/exp":{"id":"api/exponents/exp","title":"exp","description":"","sidebar":"apiSidebar"},"api/exponents/exp2":{"id":"api/exponents/exp2","title":"exp2","description":"","sidebar":"apiSidebar"},"api/exponents/expm1":{"id":"api/exponents/expm1","title":"expm1","description":"","sidebar":"apiSidebar"},"api/exponents/log":{"id":"api/exponents/log","title":"log","description":"","sidebar":"apiSidebar"},"api/exponents/log10":{"id":"api/exponents/log10","title":"log10","description":"","sidebar":"apiSidebar"},"api/exponents/log1p":{"id":"api/exponents/log1p","title":"log1p","description":"","sidebar":"apiSidebar"},"api/exponents/log2":{"id":"api/exponents/log2","title":"log2","description":"","sidebar":"apiSidebar"},"api/hyperbolic/arccosh":{"id":"api/hyperbolic/arccosh","title":"arccosh","description":"","sidebar":"apiSidebar"},"api/hyperbolic/arcsinh":{"id":"api/hyperbolic/arcsinh","title":"arcsinh","description":"","sidebar":"apiSidebar"},"api/hyperbolic/arctan2":{"id":"api/hyperbolic/arctan2","title":"arctan2","description":"","sidebar":"apiSidebar"},"api/hyperbolic/arctanh":{"id":"api/hyperbolic/arctanh","title":"arctanh","description":"","sidebar":"apiSidebar"},"api/hyperbolic/cosh":{"id":"api/hyperbolic/cosh","title":"cosh","description":"","sidebar":"apiSidebar"},"api/hyperbolic/sinc":{"id":"api/hyperbolic/sinc","title":"sinc","description":"","sidebar":"apiSidebar"},"api/hyperbolic/sinh":{"id":"api/hyperbolic/sinh","title":"sinh","description":"","sidebar":"apiSidebar"},"api/hyperbolic/tanh":{"id":"api/hyperbolic/tanh","title":"tanh","description":"","sidebar":"apiSidebar"},"api/linalg/cond":{"id":"api/linalg/cond","title":"cond","description":"","sidebar":"apiSidebar"},"api/linalg/det":{"id":"api/linalg/det","title":"det","description":"","sidebar":"apiSidebar"},"api/linalg/dot":{"id":"api/linalg/dot","title":"dot","description":"","sidebar":"apiSidebar"},"api/linalg/matmul":{"id":"api/linalg/matmul","title":"matmul","description":"","sidebar":"apiSidebar"},"api/linalg/matrix_rank":{"id":"api/linalg/matrix_rank","title":"matrix_rank","description":"","sidebar":"apiSidebar"},"api/linalg/norm":{"id":"api/linalg/norm","title":"norm","description":"","sidebar":"apiSidebar"},"api/linalg/outer":{"id":"api/linalg/outer","title":"outer","description":"","sidebar":"apiSidebar"},"api/linalg/svd":{"id":"api/linalg/svd","title":"svd","description":"","sidebar":"apiSidebar"},"api/manipulation/reshape":{"id":"api/manipulation/reshape","title":"reshape","description":"Gives a new shape to an array without changing its data.","sidebar":"apiSidebar"},"api/rounding/ceil":{"id":"api/rounding/ceil","title":"ceil","description":"","sidebar":"apiSidebar"},"api/rounding/clip":{"id":"api/rounding/clip","title":"clip","description":"","sidebar":"apiSidebar"},"api/rounding/floor":{"id":"api/rounding/floor","title":"floor","description":"","sidebar":"apiSidebar"},"api/rounding/trunc":{"id":"api/rounding/trunc","title":"trunc","description":"","sidebar":"apiSidebar"},"api/tensor/backward":{"id":"api/tensor/backward","title":"backward","description":"Computes the gradient of current tensor graph leaves.","sidebar":"apiSidebar"},"api/tensor/detach":{"id":"api/tensor/detach","title":"detach","description":"Returns a new Tensor, detached from the current graph. The result will never require gradient.","sidebar":"apiSidebar"},"api/tensor/getData":{"id":"api/tensor/getData","title":"getData","description":"","sidebar":"apiSidebar"},"api/tensor/getName":{"id":"api/tensor/getName","title":"getName","description":"","sidebar":"apiSidebar"},"api/tensor/getShape":{"id":"api/tensor/getShape","title":"getShape","description":"Returns the shape of the Tensor or 0 if the Tensor is a scalar.","sidebar":"apiSidebar"},"api/tensor/getTape":{"id":"api/tensor/getTape","title":"getTape","description":"Get current gradient tape head for self.","sidebar":"apiSidebar"},"api/tensor/grad":{"id":"api/tensor/grad","title":"grad","description":"This attribute is NULL by default and becomes a Tensor the first time a call to backward()","sidebar":"apiSidebar"},"api/tensor/graph":{"id":"api/tensor/graph","title":"graph","description":"Print the Tensor graph.","sidebar":"apiSidebar"},"api/tensor/isGPU":{"id":"api/tensor/isGPU","title":"isGPU","description":"","sidebar":"apiSidebar"},"api/tensor/isScalar":{"id":"api/tensor/isScalar","title":"isScalar","description":"Returns true if the tensor is a scalar or false if it is an n-dimensional array.","sidebar":"apiSidebar"},"api/tensor/numElements":{"id":"api/tensor/numElements","title":"numElements","description":"Returns the total number of elements in the tensor.","sidebar":"apiSidebar"},"api/tensor/requireGrad":{"id":"api/tensor/requireGrad","title":"requireGrad","description":"","sidebar":"apiSidebar"},"api/tensor/resetGradients":{"id":"api/tensor/resetGradients","title":"resetGradients","description":"","sidebar":"apiSidebar"},"api/tensor/toArray":{"id":"api/tensor/toArray","title":"toArray","description":"Converts the buffer data to a PHP object, array or scalar.","sidebar":"apiSidebar"},"api/trigonometric/acos":{"id":"api/trigonometric/acos","title":"acos","description":"","sidebar":"apiSidebar"},"api/trigonometric/arcsin":{"id":"api/trigonometric/arcsin","title":"arcsin","description":"","sidebar":"apiSidebar"},"api/trigonometric/arctan":{"id":"api/trigonometric/arctan","title":"arctan","description":"","sidebar":"apiSidebar"},"api/trigonometric/cos":{"id":"api/trigonometric/cos","title":"cos","description":"","sidebar":"apiSidebar"},"api/trigonometric/radians":{"id":"api/trigonometric/radians","title":"radians","description":"","sidebar":"apiSidebar"},"api/trigonometric/sin":{"id":"api/trigonometric/sin","title":"sin","description":"","sidebar":"apiSidebar"},"api/trigonometric/tan":{"id":"api/trigonometric/tan","title":"tan","description":"","sidebar":"apiSidebar"},"intro/autograd-intro":{"id":"intro/autograd-intro","title":"What is Automatic Differentiation (Autograd)?","description":"Automatic differentiation, often referred to as autograd, is a technique used to evaluate the derivatives of functions specified by computer programs. Unlike numerical differentiation, which approximates derivatives using finite differences, or symbolic differentiation, which manipulates mathematical expressions directly, automatic differentiation computes exact derivatives efficiently through a process of program transformation.","sidebar":"apiSidebar"},"intro/autograd-model":{"id":"intro/autograd-model","title":"Simple Neural Net from scratch using Autograd","description":"In this section, we\'ll introduce the concept of automatic differentiation (autograd) by implementing a simple","sidebar":"apiSidebar"},"intro/basic-usage":{"id":"intro/basic-usage","title":"Basic usage","description":"On this page we will see how we can use the Autograd library in a simplified way and","sidebar":"apiSidebar"},"intro/installing":{"id":"intro/installing","title":"Installing Autograd","description":"NumPower Autograd is available through composer and uses the NumPower extension and","sidebar":"apiSidebar"},"low-level/arithmetic-operand":{"id":"low-level/arithmetic-operand","title":"ArithmeticOperand Class","description":"The abstract class ArithmeticOperand allows PHP classes that extend","sidebar":"apiSidebar"},"nn/activations":{"id":"nn/activations","title":"Activations","description":"Activation functions are mathematical functions used in neural networks to introduce non-linearity into the model.","sidebar":"apiSidebar"},"nn/losses":{"id":"nn/losses","title":"Losses","description":"Loss functions are used to measure how well a model\'s predictions match the actual outcomes, providing a value that the model aims to minimize during the training process.","sidebar":"apiSidebar"}}}')}}]);