"use strict";(self.webpackChunknumpower=self.webpackChunknumpower||[]).push([[7907],{3905:(e,t,r)=>{r.d(t,{Zo:()=>l,kt:()=>m});var n=r(67294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function p(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function i(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var s=n.createContext({}),u=function(e){var t=n.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):p(p({},t),e)),r},l=function(e){var t=u(e.components);return n.createElement(s.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},y=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,a=e.originalType,s=e.parentName,l=i(e,["components","mdxType","originalType","parentName"]),c=u(r),y=o,m=c["".concat(s,".").concat(y)]||c[y]||d[y]||a;return r?n.createElement(m,p(p({ref:t},l),{},{components:r})):n.createElement(m,p({ref:t},l))}));function m(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=r.length,p=new Array(a);p[0]=y;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[c]="string"==typeof e?e:o,p[1]=i;for(var u=2;u<a;u++)p[u]=r[u];return n.createElement.apply(null,p)}return n.createElement.apply(null,r)}y.displayName="MDXCreateElement"},34314:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>s,contentTitle:()=>p,default:()=>d,frontMatter:()=>a,metadata:()=>i,toc:()=>u});var n=r(87462),o=(r(67294),r(3905));const a={},p="GPU Support",i={unversionedId:"tutorial-basics/gpu",id:"tutorial-basics/gpu",title:"GPU Support",description:"When available through an NVIDIA card with CUDA support, NumPower can store and perform operations on the graphics",source:"@site/docs/tutorial-basics/4-gpu.md",sourceDirName:"tutorial-basics",slug:"/tutorial-basics/gpu",permalink:"/numpower-docs/docs/tutorial-basics/gpu",draft:!1,editUrl:"https://github.com/NumPower/numpower-docs/docs/tutorial-basics/4-gpu.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Broadcast",permalink:"/numpower-docs/docs/tutorial-basics/broadcast"}},s={},u=[{value:"Copy NDArray to GPU",id:"copy-ndarray-to-gpu",level:2},{value:"Copy NDArray to CPU",id:"copy-ndarray-to-cpu",level:2},{value:"GPU and CPU operations",id:"gpu-and-cpu-operations",level:2}],l={toc:u},c="wrapper";function d(e){let{components:t,...r}=e;return(0,o.kt)(c,(0,n.Z)({},l,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"gpu-support"},"GPU Support"),(0,o.kt)("p",null,"When available through an NVIDIA card with CUDA support, NumPower can store and perform operations on the graphics\ncard, this is especially interesting for linear algebra operations on large tensors."),(0,o.kt)("h2",{id:"copy-ndarray-to-gpu"},"Copy NDArray to GPU"),(0,o.kt)("p",null,"To copy an ",(0,o.kt)("inlineCode",{parentName:"p"},"NDArray")," to your video card, just use the ",(0,o.kt)("inlineCode",{parentName:"p"},"gpu()")," method. This method will return a new NDArray with\nthe data copied to your VRAM."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-php"},"<?php\nuse \\NDArray as nd;\n\n$a = nd::ones([10, 10]);\n\n$a_gpu = $a->gpu();\n")),(0,o.kt)("p",null,"In this example we create an NDArray with format (10, 10) full of one. Then we use the ",(0,o.kt)("inlineCode",{parentName:"p"},"gpu()")," method to create\na ",(0,o.kt)("strong",{parentName:"p"},"copy")," of this NDArray on the GPU."),(0,o.kt)("h2",{id:"copy-ndarray-to-cpu"},"Copy NDArray to CPU"),(0,o.kt)("p",null,"In most cases, you will want your NDArray stored in your RAM. To copy an NDArray that is stored in your VRAM (GPU)\nto your RAM (CPU), just use the ",(0,o.kt)("inlineCode",{parentName:"p"},"cpu()")," method."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-php"},"<?php\nuse \\NDArray as nd;\n\n$a = nd::ones([10, 10]);\n\n$a_gpu = $a->gpu();\n\n// OPERATIONS\n\n$result = $a_gpu->cpu();\n\n")),(0,o.kt)("h2",{id:"gpu-and-cpu-operations"},"GPU and CPU operations"),(0,o.kt)("p",null,"In operations involving more than one tensor, like ",(0,o.kt)("inlineCode",{parentName:"p"},"NDArray::add"),", both tensors involved must be on the same device.\nOperations between arrays on different devices will raise an exception."),(0,o.kt)("p",null,"In this first version of NumPower, we want the user to explicitly say where they want to store their data, so\nautomatic copies between GPU and CPU are not available."),(0,o.kt)("admonition",{type:"danger"},(0,o.kt)("p",{parentName:"admonition"},"Some GPU-incompatible operations may raise an exception. In these cases the user must copy the tensor to\nthe CPU manually using the appropriate method.")))}d.isMDXComponent=!0}}]);